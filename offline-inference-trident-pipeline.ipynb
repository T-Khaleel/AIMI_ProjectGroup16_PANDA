{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18647,"databundleVersionId":1126921,"sourceType":"competition"},{"sourceId":11984578,"sourceType":"datasetVersion","datasetId":7537674},{"sourceId":11988094,"sourceType":"datasetVersion","datasetId":7540168},{"sourceId":11999543,"sourceType":"datasetVersion","datasetId":7548290},{"sourceId":11999927,"sourceType":"datasetVersion","datasetId":7548547},{"sourceId":12008469,"sourceType":"datasetVersion","datasetId":7554668},{"sourceId":12008754,"sourceType":"datasetVersion","datasetId":7554860},{"sourceId":12008764,"sourceType":"datasetVersion","datasetId":7554870},{"sourceId":12016269,"sourceType":"datasetVersion","datasetId":7559871},{"sourceId":12020155,"sourceType":"datasetVersion","datasetId":7562458},{"sourceId":12024268,"sourceType":"datasetVersion","datasetId":7565103}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Part 1: First get the titan, phikon encoder and hest segmenter offline\n","metadata":{}},{"cell_type":"markdown","source":"## Part 1: Import\n","metadata":{}},{"cell_type":"code","source":"import os, sys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:26.422493Z","iopub.execute_input":"2025-05-30T15:54:26.422978Z","iopub.status.idle":"2025-05-30T15:54:26.428021Z","shell.execute_reply.started":"2025-05-30T15:54:26.422938Z","shell.execute_reply":"2025-05-30T15:54:26.427006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Part 1: obtaining everything offline","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/TITAN_combined\n!mkdir -p /kaggle/working/TITAN_combined/titan\n!cp -r /kaggle/input/titana/TITAN/* /kaggle/working/TITAN_combined/\n!cp -r /kaggle/input/titan-weights/titan-model/* /kaggle/working/TITAN_combined/titan/\n!ls /kaggle/working/TITAN_combined/titan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:26.429466Z","iopub.execute_input":"2025-05-30T15:54:26.429864Z","iopub.status.idle":"2025-05-30T15:54:40.507614Z","shell.execute_reply.started":"2025-05-30T15:54:26.429803Z","shell.execute_reply":"2025-05-30T15:54:40.506243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --no-deps /kaggle/input/einops/einops_pkgs/einops_pkgs/*.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:40.509065Z","iopub.execute_input":"2025-05-30T15:54:40.509369Z","iopub.status.idle":"2025-05-30T15:54:46.103173Z","shell.execute_reply.started":"2025-05-30T15:54:40.509339Z","shell.execute_reply":"2025-05-30T15:54:46.101312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sys.path.insert(0, \"/kaggle/working/TITAN_combined\")  # so “import titan” picks up your local code\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:46.105869Z","iopub.execute_input":"2025-05-30T15:54:46.106150Z","iopub.status.idle":"2025-05-30T15:54:46.111042Z","shell.execute_reply.started":"2025-05-30T15:54:46.106124Z","shell.execute_reply":"2025-05-30T15:54:46.110155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\ngrep -R \"def encode_slide_from_patch_features\" -n /kaggle/working/TITAN_combined/titan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:46.111936Z","iopub.execute_input":"2025-05-30T15:54:46.112247Z","iopub.status.idle":"2025-05-30T15:54:47.999136Z","shell.execute_reply.started":"2025-05-30T15:54:46.112224Z","shell.execute_reply":"2025-05-30T15:54:47.998041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\ngrep -nE \"^class \" /kaggle/working/TITAN_combined/titan/modeling_titan.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:48.000281Z","iopub.execute_input":"2025-05-30T15:54:48.000614Z","iopub.status.idle":"2025-05-30T15:54:48.013822Z","shell.execute_reply.started":"2025-05-30T15:54:48.000583Z","shell.execute_reply":"2025-05-30T15:54:48.012569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sys.path.insert(0, \"/kaggle/working/TITAN_combined\")  # your offline code\n\nimport torch\nfrom titan.configuration_titan import TitanConfig\nfrom titan.modeling_titan import Titan   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:54:48.015016Z","iopub.execute_input":"2025-05-30T15:54:48.015393Z","iopub.status.idle":"2025-05-30T15:55:34.460480Z","shell.execute_reply.started":"2025-05-30T15:54:48.015367Z","shell.execute_reply":"2025-05-30T15:55:34.459320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Load the config\nconfig = TitanConfig.from_pretrained(\n    \"/kaggle/working/TITAN_combined/titan\",\n    local_files_only=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:34.461736Z","iopub.execute_input":"2025-05-30T15:55:34.462590Z","iopub.status.idle":"2025-05-30T15:55:34.471118Z","shell.execute_reply.started":"2025-05-30T15:55:34.462553Z","shell.execute_reply":"2025-05-30T15:55:34.470056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\ngrep -nE \"^class \" /kaggle/working/TITAN_combined/titan/modeling_titan.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:34.472555Z","iopub.execute_input":"2025-05-30T15:55:34.472938Z","iopub.status.idle":"2025-05-30T15:55:34.511919Z","shell.execute_reply.started":"2025-05-30T15:55:34.472903Z","shell.execute_reply":"2025-05-30T15:55:34.511083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n#  remove any HuggingFace module cache for titan\nrm -rf ~/.cache/huggingface/modules/transformers_modules/titan\n\n# uninstall any pip-installed 'titan' package\npip uninstall -y titan\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:34.514793Z","iopub.execute_input":"2025-05-30T15:55:34.515082Z","iopub.status.idle":"2025-05-30T15:55:36.331461Z","shell.execute_reply.started":"2025-05-30T15:55:34.515062Z","shell.execute_reply":"2025-05-30T15:55:36.330279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  force Transformers / HF Hub to stay offline\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\nos.environ[\"HF_HUB_OFFLINE\"]   = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:36.332571Z","iopub.execute_input":"2025-05-30T15:55:36.332920Z","iopub.status.idle":"2025-05-30T15:55:36.339248Z","shell.execute_reply.started":"2025-05-30T15:55:36.332892Z","shell.execute_reply":"2025-05-30T15:55:36.337908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sys.path.insert(0, \"/kaggle/working/TITAN_combined\")\nfrom transformers import PreTrainedTokenizerFast\n_orig = PreTrainedTokenizerFast.from_pretrained\ndef _local_tok(repo_id, *args, **kw):\n    if repo_id == \"MahmoodLab/TITAN\":\n        return _orig(\"/kaggle/working/TITAN_combined/titan\", local_files_only=True, *args, **kw)\n    return _orig(repo_id, *args, **kw)\nPreTrainedTokenizerFast.from_pretrained = _local_tok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:36.340459Z","iopub.execute_input":"2025-05-30T15:55:36.341485Z","iopub.status.idle":"2025-05-30T15:55:36.362504Z","shell.execute_reply.started":"2025-05-30T15:55:36.341445Z","shell.execute_reply":"2025-05-30T15:55:36.361452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## titan offline model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom titan.configuration_titan import TitanConfig\nfrom titan.modeling_titan      import Titan\nconfig = TitanConfig.from_pretrained(\"/kaggle/working/TITAN_combined/titan\", local_files_only=True)\nmodel  = Titan.from_pretrained(\"/kaggle/working/TITAN_combined/titan\", config=config, local_files_only=True ).eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:36.363808Z","iopub.execute_input":"2025-05-30T15:55:36.364142Z","iopub.status.idle":"2025-05-30T15:55:36.828996Z","shell.execute_reply.started":"2025-05-30T15:55:36.364117Z","shell.execute_reply":"2025-05-30T15:55:36.827965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## get the hest-segmenter","metadata":{}},{"cell_type":"code","source":"sys.path.append('/kaggle/input/trident-orig/TRIDENT')\nfrom trident import load_wsi\nfrom trident.segmentation_models.load import HESTSegmenter\nfrom trident.segmentation_models import segmentation_model_factory\n\ndef offline_build(self):\n    from torchvision.models.segmentation import deeplabv3_resnet50\n    import torchvision.transforms as transforms\n    import torch.nn as nn\n    import torch\n    weights_path = \"/kaggle/input/hest-tissue-seg-weights/deeplabv3_seg_v4.ckpt\"\n    model = deeplabv3_resnet50(weights=None, weights_backbone=None)\n    model.classifier[4] = nn.Conv2d(256, 2, kernel_size=1, stride=1)\n    checkpoint = torch.load(weights_path, map_location='cpu')\n    state_dict = {k.replace('model.', ''): v for k, v in checkpoint.get('state_dict', {}).items() if 'aux' not in k}\n    model.load_state_dict(state_dict)\n    self.input_size = 512\n    self.precision = torch.float16\n    self.target_mag = 10\n    eval_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n                             std=(0.229, 0.224, 0.225))\n    ])\n    return model, eval_transforms\n\nHESTSegmenter._build = offline_build\n\nseg_model = segmentation_model_factory(\n    \"hest\",\n    confidence_thresh=0.5\n)\n\nprint(\"Segmentation model ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:36.830410Z","iopub.execute_input":"2025-05-30T15:55:36.830798Z","iopub.status.idle":"2025-05-30T15:55:43.055643Z","shell.execute_reply.started":"2025-05-30T15:55:36.830761Z","shell.execute_reply":"2025-05-30T15:55:43.054596Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## get the titan encoder, phikon encoder via trident","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/trident-orig/TRIDENT')\n\n# import encoder factories\nfrom trident.patch_encoder_models.load import encoder_factory as patch_encoder_factory\nfrom trident.slide_encoder_models.load import encoder_factory as slide_encoder_factory\n\n# load the Phikon encoder (patch-level) from local path\nphikon_encoder = patch_encoder_factory(\n    \"phikon\",\n    weights_path=\"/kaggle/input/phikon-model/phikon_model/pytorch_model.bin\"\n)\nprint(\" Phikon encoder loaded:\")\n# print(phikon_encoder)\ntitan_encoder = slide_encoder_factory('titan',pretrained=True)\nprint(\" Titan encoder loaded\")\n# print(titan_encoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:55:43.056773Z","iopub.execute_input":"2025-05-30T15:55:43.057712Z","iopub.status.idle":"2025-05-30T15:55:43.887790Z","shell.execute_reply.started":"2025-05-30T15:55:43.057686Z","shell.execute_reply":"2025-05-30T15:55:43.886839Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Part 2: The real inference of our best trained models","metadata":{}},{"cell_type":"markdown","source":"### part 2: imports","metadata":{}},{"cell_type":"code","source":"# Core Libraries\nimport pytorch_lightning as pl\nimport time\nimport os\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport h5py\nfrom pathlib import Path\nfrom PIL import Image\nimport numpy as np\nimport imagehash\nfrom openslide import OpenSlide\nimport pandas as pd\n\n# Geospatial libraries\nimport geopandas as gpd\n\n# Utilities\nimport shutil\nimport zipfile\n\n# Monkey-patch for GeoPandas\nif not hasattr(gpd.GeoSeries, \"union_all\"):\n    gpd.GeoSeries.union_all = lambda self, *args, **kwargs: self.unary_union","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Configuration","metadata":{}},{"cell_type":"code","source":"class Config:\n    def __init__(self):\n        self.input_dim = 768\n        self.hidden_dim = 512\n        self.num_classes = 5\n        self.lr = 3e-4\n        self.batch_size = 32\n        self.max_epochs = 50\n        self.num_workers = 4\n        self.n_splits = 5\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.patch_encoder_name = \"phikon\"\n        self.slide_encoder_name = \"titan\"\n        self.patch_mag = 10\n        self.patch_size = 224\n\n        # paths\n        self.data_dir = \"/kaggle/input/prostate-cancer-grade-assessment\"\n        self.train_images_dir = os.path.join(self.data_dir, \"train_images\")\n        self.test_images_dir = os.path.join(self.data_dir, \"test_images\")\n        self.train_csv = os.path.join(self.data_dir, \"train.csv\")\n        self.test_csv = os.path.join(self.data_dir, \"test.csv\")\n        self.sample_submission = os.path.join(self.data_dir, \"sample_submission.csv\")\n        self.best_models = \"/kaggle/input/model-label-denoised\"\n        self.output_dir = \"/kaggle/working/slide_vectors\"\n        self.submission_output = \"submission.csv\"\n        \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Simple Classifier","metadata":{}},{"cell_type":"code","source":"class SlideClassifier(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.save_hyperparameters(cfg.__dict__)\n        self.head = nn.Sequential(\n            nn.Linear(cfg.input_dim, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.3),\n            nn.Linear(128, cfg.num_classes)\n        )\n        self.criterion = nn.BCEWithLogitsLoss()\n        self.val_preds = []\n        self.val_targets = []\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.kaiming_normal_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        return self.head(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test Custom dataset needed for the dataloader","metadata":{}},{"cell_type":"code","source":"class SlideTestDataset(Dataset):\n    def __init__(self, slide_vectors):\n        self.slide_ids = list(slide_vectors.keys())\n        self.slide_vectors = slide_vectors\n\n    def __len__(self):\n        return len(self.slide_ids)\n\n    def __getitem__(self, idx):\n        slide_id = self.slide_ids[idx]\n        vector = self.slide_vectors[slide_id]\n        return slide_id, vector","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Exctracting all features with Phikon and Titan","metadata":{}},{"cell_type":"code","source":"def extract_test_features(cfg,phikon_encoder,titan_encoder,seg_model):\n    print(\"Start feature extraction on the test set ..\")\n\n    is_test = os.path.exists(cfg.test_images_dir)\n    image_folder = cfg.test_images_dir if is_test else cfg.train_images_dir\n    print(f\"Using images from: {image_folder}\")\n\n    # Step 1: create the slide_paths\n    if not is_test:\n        print(\"No Test images found! Only use the first 100 training slides\")\n        df_train = pd.read_csv(cfg.train_csv)\n        fallback_ids = df_train.loc[:10, \"image_id\"].tolist()\n        slide_paths = [Path(image_folder) / f\"{sid}.tiff\" for sid in fallback_ids]\n    else:\n        slide_paths = list(Path(image_folder).glob(\"*.tiff\"))\n\n    slide_paths.sort(key=lambda x: x.name)\n\n     # Step 2: Load Trident models\n    seg = seg_model\n    patch_encoder = phikon_encoder\n    slide_encoder = titan_encoder\n\n    slide_vectors = {}\n\n    # step 3: go through the loop\n    for idx, slide_path in enumerate(slide_paths, 1):\n        try:\n            job_dir = Path(cfg.output_dir) / slide_path.stem\n            job_dir.mkdir(parents=True, exist_ok=True)\n\n            print(f\" Processing {slide_path.name}...\")\n            wsi = load_wsi(slide_path, lazy_init=False)\n\n            # Tissue segmentation\n            wsi.segment_tissue(seg, seg.target_mag, job_dir, cfg.device)\n\n            # Extract patch coordinates\n            coords_path = wsi.extract_tissue_coords(\n                target_mag=cfg.patch_mag,\n                patch_size=cfg.patch_size,\n                save_coords=str(job_dir),\n            )\n\n            # Extract patch features (saved to job_dir/patches/)\n            patch_features_path = wsi.extract_patch_features(\n                patch_encoder=patch_encoder,\n                coords_path=str(coords_path),\n                save_features=str(job_dir),\n                device=cfg.device,\n                batch_limit=32,\n            )\n\n            # create embeddings directory and extract slide-level features\n            embeddings_dir = job_dir / \"embeddings\"\n            embeddings_dir.mkdir(parents=True, exist_ok=True)\n\n            slide_vector_path = wsi.extract_slide_features(\n                str(patch_features_path),\n                slide_encoder,\n                str(embeddings_dir),\n                cfg.device\n            )\n            embeddings_h5 = embeddings_dir / f\"{slide_path.stem}.h5\"\n            if embeddings_h5.exists():\n                with h5py.File(embeddings_h5, \"r\") as f:\n                    features = f[\"features\"][:]\n                    tensor = torch.from_numpy(features)\n                    slide_vectors[slide_path.stem] = tensor\n            else:\n                print(f\"Warning: embeddings .h5 not found for {slide_path.stem}\")\n\n        except Exception as e:\n            print(f\"Error processing {slide_path.name}: {e}\")\n\n    print(f\"Done extracting features for {len(slide_vectors)} slides.\")\n    return slide_vectors\n            \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Run inference\n","metadata":{}},{"cell_type":"code","source":"def run_inference(cfg):\n    # create slide_vectors\n    slide_vectors = extract_test_features(cfg, phikon_encoder, titan_encoder, seg_model)\n\n    if not slide_vectors:\n        print(\"No slide features extracted. Creating dummy submission...\")\n        dummy_df = pd.read_csv(cfg.sample_submission)\n        dummy_df[\"isup_grade\"] = 0\n        dummy_df.to_csv(cfg.submission_output, index=False)\n        print(f\"Dummy submission saved at {cfg.submission_output}\")\n        return\n\n    # create dataset and dataloader\n    dataset = SlideTestDataset(slide_vectors)\n    slide_ids = [dataset.slide_ids[i] for i in range(len(dataset))]\n    dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n\n    # load in all best fold model classifiers\n    fold_ckpts = sorted(Path(cfg.best_models).glob(\"fold*.ckpt\"))\n    print(f\"Using {len(fold_ckpts)} models for ensemble: {fold_ckpts}\")\n\n    all_preds = []\n\n    for ckpt_path in fold_ckpts:\n        print(f\"Loading model: {ckpt_path}\")\n        model = SlideClassifier.load_from_checkpoint(ckpt_path, cfg=cfg)\n        model.eval().to(cfg.device)\n\n        preds = []\n\n        with torch.no_grad():\n            for batch_slide_ids, vectors in dataloader:\n                vectors = vectors.to(cfg.device)\n                logits = model(vectors)\n\n                # convert the logits to ordinal predictions\n                ordinal_preds = (torch.sigmoid(logits) > 0.5).float().cpu().numpy()\n                final_preds = ordinal_preds.sum(axis=1)  \n\n                preds.extend(final_preds.astype(int))\n\n        all_preds.append(preds)\n\n    # average across fold, ensemble  method\n    final_preds = np.round(np.mean(all_preds, axis=0)).astype(int)\n\n    # final submission\n    df_train = pd.read_csv(cfg.train_csv)\n    df_test = pd.read_csv(cfg.test_csv)\n    is_test = os.path.exists(cfg.test_images_dir)\n\n    df = df_test if is_test else df_train.loc[:len(final_preds) - 1]\n    df[\"isup_grade\"] = final_preds.astype(int)\n\n    submission_df = df[[\"image_id\", \"isup_grade\"]]\n    submission_df.to_csv(cfg.submission_output, index=False)\n    print(f\"Inference done! Submission saved as {cfg.submission_output}\")\n\n    # to ensure it comes trough the submission on kaggle\n    if os.path.exists(f'../input/prostate-cancer-grade-assessment/test_images'):\n        print(\"Still can not access the test file?\")\n        submission_df.to_csv(cfg.submission_output, index=False)\n    else:\n        # fallback to Kaggle sample submission\n        sample_df = pd.read_csv(\"/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv\")\n        sample_df.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    cfg = Config()\n    run_inference(cfg)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}